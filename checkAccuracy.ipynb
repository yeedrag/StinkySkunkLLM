{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m csv_path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     50\u001b[0m csv_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test_smiles_reg.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 51\u001b[0m repeated_materials, matching_material_count, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_csvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of repeated materials in the first CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepeated_materials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaterials in the first CSV that are also in the second CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatching_material_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m, in \u001b[0;36mcompare_csvs\u001b[1;34m(csv_path1, csv_path2)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load the CSV files into pandas DataFrames\u001b[39;00m\n\u001b[0;32m     17\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path1)\n\u001b[1;32m---> 18\u001b[0m df2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterial\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: Chem\u001b[38;5;241m.\u001b[39mCanonSmiles(x))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#df2['Material'].apply(lambda x: Chem.CanonSmiles(x))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate the number of repeated materials in the first CSV\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yeedrag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeedrag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:624\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeedrag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1921\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1914\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1916\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m     (\n\u001b[0;32m   1918\u001b[0m         index,\n\u001b[0;32m   1919\u001b[0m         columns,\n\u001b[0;32m   1920\u001b[0m         col_dict,\n\u001b[1;32m-> 1921\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\yeedrag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "def compare_csvs(csv_path1, csv_path2):\n",
    "    \"\"\"\n",
    "    Compare two CSV files in terms of repeated materials, matching materials, and accuracy based on value comparison.\n",
    "\n",
    "    Parameters:\n",
    "    csv_path1 (str): Path to the first CSV file.\n",
    "    csv_path2 (str): Path to the second CSV file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the number of repeated materials in the first CSV,\n",
    "           the number of materials in the first CSV that are also in the second CSV,\n",
    "           and the accuracy of these materials' values being within a 10% error margin.\n",
    "    \"\"\"\n",
    "    # Load the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(csv_path1)\n",
    "    df2 = pd.read_csv(csv_path2)\n",
    "    df1['Material'].apply(lambda x: Chem.CanonSmiles(x))\n",
    "    #df2['Material'].apply(lambda x: Chem.CanonSmiles(x))\n",
    "    # Calculate the number of repeated materials in the first CSV\n",
    "    repeated_materials = df1.duplicated(subset=['Material']).sum()\n",
    "\n",
    "    # Group duplicated materials\n",
    "    df1 = df1.groupby('Material')['Value'].apply(list).reset_index()\n",
    "    print(df1.head)\n",
    "    print(df2.head)\n",
    "    # Find materials in the first CSV that are also in the second CSV\n",
    "    matching_materials = pd.merge(df1, df2, on='Material', how='inner', suffixes=('_x', '_y'))\n",
    "    # Function to check if the values are within a 10% error margin\n",
    "    def is_within_10_percent(row):\n",
    "        if(row['Value_y'] == 0):\n",
    "            return all(abs(gpt_value - row['Value_y']) <= 5 for gpt_value in row['Value_x'])\n",
    "        return all(abs(gpt_value - row['Value_y']) / row['Value_y'] <= 0.1 for gpt_value in row['Value_x'])\n",
    "\n",
    "    print(matching_materials.head)\n",
    "    # Apply the function to determine correctness\n",
    "    matching_materials['is_correct'] = matching_materials.apply(is_within_10_percent, axis=1)\n",
    "\n",
    "    # Count how many are correct\n",
    "    correct_count = matching_materials['is_correct'].sum()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / len(matching_materials) if len(matching_materials) > 0 else 0\n",
    "\n",
    "    return repeated_materials, len(matching_materials), accuracy\n",
    "\n",
    "# Example usage\n",
    "csv_path1 = 'test.csv'\n",
    "csv_path2 = '../test_smiles_reg.csv'\n",
    "repeated_materials, matching_material_count, accuracy = compare_csvs(csv_path1, csv_path2)\n",
    "\n",
    "print(f\"Number of repeated materials in the first CSV: {repeated_materials}\")\n",
    "print(f\"Materials in the first CSV that are also in the second CSV: {matching_material_count}\")\n",
    "print(f\"Accuracy (materials within 10% error margin): {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path2 = '../test_smiles_reg.csv'\n",
    "df2 = pd.read_csv(csv_path2)\n",
    "df2['Value'] = df2['Value'].str.strip('[]').astype(float)\n",
    "#df2['Material'].apply(lambda x: Chem.CanonSmiles(x))\n",
    "df2.to_csv('../test_smiles_reg.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Duplicate Materials in df1': 613, 'Unique Materials in Both df1 and df2': 0, 'Overall Accuracy': 0.0, 'Accuracy for Unique Materials': nan}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_csvs(csv_path1, csv_path2):\n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(csv_path1)\n",
    "    df2 = pd.read_csv(csv_path2)\n",
    "    \n",
    "    # Step 1: Canonicalize SMILES strings in df1 (assuming external canonicalization)\n",
    "    # Note: This step is assumed to be done prior or outside this function due to RDKit dependency.\n",
    "    df1['Material'].apply(lambda x: Chem.CanonSmiles(x))\n",
    "    # Step 2: Identify duplicate materials in df1\n",
    "    duplicate_materials_count = df1.duplicated('Material', keep=False).sum()\n",
    "    \n",
    "    # Step 3: Find unique materials in both df1 and df2\n",
    "    unique_materials_df1 = pd.unique(df1['Material'])\n",
    "    unique_materials_df2 = pd.unique(df2['Material'])\n",
    "    unique_in_both = len(set(unique_materials_df1).intersection(set(unique_materials_df2)))\n",
    "    # Define a function to check if the value in df1 falls within the desired range for the same material in df2\n",
    "    def is_correct_prediction(row, df2):\n",
    "        material = row['Material']\n",
    "        value = row['Value']\n",
    "        df2_values = df2[df2['Material'] == material]['Value']\n",
    "        min_value = df2_values.min() * 0.9\n",
    "        max_value = df2_values.max() * 1.1\n",
    "        return min_value <= value <= max_value\n",
    "    \n",
    "    # Step 4: Calculate Overall Accuracy for df1\n",
    "    df1['Correct Prediction'] = df1.apply(is_correct_prediction, df2=df2, axis=1)\n",
    "    overall_accuracy = df1['Correct Prediction'].mean()\n",
    "    \n",
    "    # Step 5: Calculate Accuracy for Unique Materials\n",
    "    unique_materials_in_both = df1[df1['Material'].isin(unique_materials_df2)]\n",
    "    unique_accuracy = unique_materials_in_both['Correct Prediction'].mean()\n",
    "    \n",
    "    return {\n",
    "        'Duplicate Materials in df1': duplicate_materials_count,\n",
    "        'Unique Materials in Both df1 and df2': unique_in_both,\n",
    "        'Overall Accuracy': overall_accuracy,\n",
    "        'Accuracy for Unique Materials': unique_accuracy\n",
    "    }\n",
    "\n",
    "# You can call this function with the paths to your CSV files:\n",
    "csv_path1 = 'PolymerTransitionTemperature_SMILES_1_2024_03_19-121341.csv'\n",
    "csv_path2 = '../test_smiles_reg.csv'\n",
    "results = compare_csvs(csv_path1, csv_path2)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=CC\n"
     ]
    }
   ],
   "source": [
    "print(Chem.CanonSmiles(\"CC=C\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
